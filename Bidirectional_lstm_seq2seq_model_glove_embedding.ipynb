{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5423575",
   "metadata": {},
   "source": [
    "In this bidirectional lstm model ,the code idea has been taken from \"LSTM donor choose data\".The difference is in model architecture where we are using functional api,rest everything is same as base model except some change in target \"y\".<br>\n",
    "In this  model what we will do is we will using glove embedding to create embedding layer and also tokenize and pad sequences the text and sentiment column. the target will be selected_text column but it will not be possible to predict selected_text directlyl ,but with bidirectional lstm model to predict selected_text so what we will do is we will come up with two new columns for target variable ,these two columns will show the start index and end index of selected_text on text column and then based on start and end index we will create  array of indices from start to end and the word having common in text and selected text will be assigned as 1 and uncommon words will be assigned as 0.<br>\n",
    "for example:\n",
    "\n",
    "text | selected_text | start_index | end_index |\n",
    ":---: | :---: | :---: | :---: |\n",
    "my boss is bullying me | bullying me | 3 | 4|\n",
    "what interview leave me alone | leave me alone | 2 | 4|\n",
    "\n",
    "array will be :<br>\n",
    "y_1 = [0,0,1,1]<br>\n",
    "y_2 = [0,1,1,1,0] and so on<br>\n",
    "\n",
    "the length of array will be max length of sentence in text column,for eg in above two sentence thelength is 5 so array is also of length 5 where common words are assigned 1 and rest index as 0.\n",
    "\n",
    "so you can see above \"bullying me\" start from 3rd index in text column and end at 4th index in text column,so  now we will use two newly created columns as target variable and during prediction will replace index with words,<br>This is the **BiDirectional LSTM  MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4940285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy.stats as st\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpl_patches\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.lines as mlines\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop=set(stopwords.words('english'))\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')  \n",
    "nltk.download('vader_lexicon')\n",
    "import spacy\n",
    "from collections import defaultdict,Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.util import ngrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "\n",
    "from textstat import flesch_reading_ease\n",
    "tqdm.pandas()\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Input,GRU,LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding,Dense,Dropout,Concatenate,Flatten,Input,GRU,BatchNormalization,Bidirectional,SpatialDropout1D,LSTM,LayerNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler,ModelCheckpoint,EarlyStopping,TensorBoard,ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20b23abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>i`d have responded if i were going</td>\n",
       "      <td>i`d have responded if i were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>sooo sad</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                        text  \\\n",
       "0  cb774db0d1          i`d have responded if i were going   \n",
       "1  549e992a42  sooo sad i will miss you here in san diego   \n",
       "\n",
       "                        selected_text sentiment  \n",
       "0  i`d have responded if i were going   neutral  \n",
       "1                            sooo sad  negative  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train_Preprocessed_final.csv')\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ed5588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>last session of the day</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  f87dea47db                            last session of the day   neutral\n",
       "1  96d74cb729  shanghai is also really exciting precisely sky...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test_preprocessed_final.csv')\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f07c4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data has a shape of :  (27468, 4)\n",
      "The test data has a shape of :  (3533, 3)\n"
     ]
    }
   ],
   "source": [
    "print('The training data has a shape of : ',df_train.shape)\n",
    "print('The test data has a shape of : ',df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d01cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_index(data):\n",
    "    '''This function will find the starting index from text column where words from selected_text starts\n",
    "    text == attribute1\n",
    "    selected_text == attribute2'''\n",
    "    attribute1 = data[0]\n",
    "    attribute2 = data[1]\n",
    "    attribute1 = attribute1.split()\n",
    "    attribute2 = attribute2.split()\n",
    "    end = attribute2[0]\n",
    "    starting_index = attribute1.index(end)\n",
    "    return starting_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5b5ee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_index(data):\n",
    "    '''This function will find the ending index from text column where words from selected_text starts\n",
    "    text == attribute1\n",
    "    selected_text == attribute2\n",
    "    start_index == attribute3'''\n",
    "    attribute1 = data[0]\n",
    "    attribute2 = data[1]\n",
    "    attribute3 = data[2]\n",
    "    attribute2 = attribute2.split()\n",
    "    end = attribute2[-1]\n",
    "    try:\n",
    "        ending_index = attribute1.index(end,attribute3)\n",
    "    except:\n",
    "        ending_index = attribute1.index(end)\n",
    "        \n",
    "    return ending_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d695ad0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 27468/27468 [00:00<00:00, 65655.74it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train['starting_index'] = df_train[['text','selected_text']].progress_apply(lambda i : start_index(i),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d85f6d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 27468/27468 [00:00<00:00, 55971.90it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train['ending_index'] = df_train[['text','selected_text','starting_index']].progress_apply(lambda i : end_index(i),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a59370",
   "metadata": {},
   "source": [
    "#### checking whether ending index < starting index and if yes removing that row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62b9cb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train.ending_index<df_train.starting_index].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4c5d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will take only those rows where ending_index >= starting index\n",
    "df_train = df_train[df_train.ending_index >= df_train.starting_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05a33915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27445, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5c0ebf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>starting_index</th>\n",
       "      <th>ending_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>i`d have responded if i were going</td>\n",
       "      <td>i`d have responded if i were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>sooo sad</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of CURSE why couldn`t they put them on th...</td>\n",
       "      <td>sons of CURSE</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                 i`d have responded if i were going   \n",
       "1  549e992a42         sooo sad i will miss you here in san diego   \n",
       "2  088c60f138                             my boss is bullying me   \n",
       "3  9642c003ef                      what interview leave me alone   \n",
       "4  358bd9e861  sons of CURSE why couldn`t they put them on th...   \n",
       "\n",
       "                        selected_text sentiment  starting_index  ending_index  \n",
       "0  i`d have responded if i were going   neutral               0             6  \n",
       "1                            sooo sad  negative               0             1  \n",
       "2                         bullying me  negative               3             4  \n",
       "3                      leave me alone  negative               2             4  \n",
       "4                       sons of CURSE  negative               0             2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3af1ddc",
   "metadata": {},
   "source": [
    "## Train Validation Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54f017d",
   "metadata": {},
   "source": [
    "#### Finding maximum length of sentence in text column from original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14ac8e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum length of sentence in text column is :  32\n"
     ]
    }
   ],
   "source": [
    "df_train['text_word_length'] = df_train['text'].astype('str').apply(lambda i : len(i.split()))\n",
    "max_sentence_length = df_train['text_word_length'].max()\n",
    "print('The maximum length of sentence in text column is : ',max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fae35594",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[[\"text\",\"selected_text\",\"sentiment\",\"starting_index\",\"ending_index\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69a8c522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27445it [00:00, 429988.58it/s]\n"
     ]
    }
   ],
   "source": [
    "y = np.zeros((X.shape[0],max_sentence_length+1))\n",
    "for i,j in tqdm(enumerate(X.values)):\n",
    "    ini_start_index = j[3] \n",
    "    fin_end_index = j[4]\n",
    "    y[i][ini_start_index : fin_end_index+1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95980e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data :  ['is feeling so giddy and wanna go home' 'giddy' 'negative' 3 3]\n",
      "\n",
      "\n",
      "the output y : [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "****************************************************************************************************\n",
      "original data :  ['so no yarn arriving until monday and i don`t even know what`s in this shipment i have nothing to dye now what'\n",
      " 'i have nothing to dye' 'negative' 7 19]\n",
      "\n",
      "\n",
      "the output y : [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Check the output y \n",
    "import random\n",
    "for i in range(2):\n",
    "    index = random.randint(0,df_train.shape[0])\n",
    "    print(\"original data : \",X.values[index])\n",
    "    print(\"\\n\")\n",
    "    print(\"the output y :\",y[index])\n",
    "    print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af5dc41",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "From above output you can see the the words at selected text column which are common to text column are assigned as 1 rest as 0 and the length of array is equal to meax length of sentence in text column which was designated by \"max_sentence_length\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e2de3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The X data has a shape of :  (27445, 5)\n",
      "The y data has a shape of :  (27445, 33)\n"
     ]
    }
   ],
   "source": [
    "print('The X data has a shape of : ',X.shape)\n",
    "print('The y data has a shape of : ',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23bf81a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of X_train is :  (21956, 5)\n",
      "the shape of X_valid is :  (5489, 5)\n",
      "the shape of y_train is :  (21956, 33, 1)\n",
      "the shape of y_valid is :  (5489, 33, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X,y,test_size=0.20,random_state=42)\n",
    "#Preparing the y_train and y_valid from 2D to 3D tensor for seq to seq architecture\n",
    "y_train=np.expand_dims(y_train,-1)\n",
    "y_valid = np.expand_dims(y_valid,-1)\n",
    "print('the shape of X_train is : ',X_train.shape)\n",
    "print('the shape of X_valid is : ',X_valid.shape)\n",
    "print('the shape of y_train is : ',y_train.shape)\n",
    "print('the shape of y_valid is : ',y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af92408e",
   "metadata": {},
   "source": [
    "## \"Text\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfb7116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_train = X_train['text'].values\n",
    "df_text_valid = X_valid['text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e07e39",
   "metadata": {},
   "source": [
    "#### Tokenizer and Pad sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c81cca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20710\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "text_tknz = Tokenizer(lower=True,split=' ',oov_token='oov')\n",
    "text_tknz.fit_on_texts(df_text_train)\n",
    "df_text_train = text_tknz.texts_to_sequences(df_text_train)\n",
    "df_text_valid = text_tknz.texts_to_sequences(df_text_valid)\n",
    "text_vocab_size = len(text_tknz.word_index)+1\n",
    "print(text_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7aa05a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of text train after padding :  (21956, 32)\n",
      "the shape of text valid after padding :  (5489, 32)\n"
     ]
    }
   ],
   "source": [
    "text_max_length = 32\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "df_text_train = pad_sequences(df_text_train,maxlen=text_max_length,padding='post')\n",
    "df_text_valid = pad_sequences(df_text_valid,maxlen=text_max_length,padding='post')\n",
    "\n",
    "print('the shape of text train after padding : ',df_text_train.shape)\n",
    "print('the shape of text valid after padding : ',df_text_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7364d067",
   "metadata": {},
   "source": [
    "#### Emdedding Matrix\n",
    "#https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "793888ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "embeddings_index = dict()\n",
    "with open('glove.6B.300dd.txt',encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    \n",
    "print(len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf6db144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20710, 300)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = zeros((text_vocab_size, 300))\n",
    "for word, i in text_tknz.word_index.items():\n",
    "  embedding_vector = embeddings_index.get(word)\n",
    "  if embedding_vector is not None:\n",
    "    embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21cf83f",
   "metadata": {},
   "source": [
    "## \"Sentiment\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b54e9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment_train = X_train['sentiment'].values\n",
    "df_sentiment_valid = X_valid['sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c5999f",
   "metadata": {},
   "source": [
    "#### Tokenizer and Pad sequencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d32c9234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "sentiment_tknz = Tokenizer(lower=True,split=' ',oov_token='oov')\n",
    "sentiment_tknz.fit_on_texts(df_sentiment_train)\n",
    "df_sentiment_train = sentiment_tknz.texts_to_sequences(df_sentiment_train)\n",
    "df_sentiment_valid = sentiment_tknz.texts_to_sequences(df_sentiment_valid)\n",
    "sentiment_vocab_size = len(sentiment_tknz.word_index)+1\n",
    "print(sentiment_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "676e92cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of sentiment train after padding :  (21956, 1)\n",
      "the shape of sentiment valid after padding :  (5489, 1)\n"
     ]
    }
   ],
   "source": [
    "sentiment_max_length = 1\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "df_sentiment_train = pad_sequences(df_sentiment_train,maxlen=sentiment_max_length,padding='post')\n",
    "df_sentiment_valid = pad_sequences(df_sentiment_valid,maxlen=sentiment_max_length,padding='post')\n",
    "\n",
    "print('the shape of sentiment train after padding : ',df_sentiment_train.shape)\n",
    "print('the shape of sentiment valid after padding : ',df_sentiment_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43e2333",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM Seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37f0ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding,Dense,LSTM,Dropout,Concatenate,Flatten,TimeDistributed,Input,GRU,BatchNormalization,Bidirectional,SpatialDropout1D,LSTM,LayerNormalization\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ec8c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/timedistributed-layer-for-long-short-term-memory-networks-in-python/\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "#Text column input\n",
    "text_input = Input(shape=(text_max_length,))\n",
    "#Sentiment column input\n",
    "sentiment_input = Input(shape=(sentiment_max_length,))\n",
    "#Concatinating both inputs\n",
    "concat= Concatenate()([text_input,sentiment_input])\n",
    "embedding_text = Embedding(text_vocab_size,300,input_length=text_max_length,\\\n",
    "                      trainable=False,mask_zero = True,embeddings_initializer=tf.constant_initializer(embedding_matrix))(concat)\n",
    "bilstm_layer = Bidirectional(LSTM(128,return_sequences=True,dropout=0.4))(embedding_text)\n",
    "\n",
    "dense_layer_1 = Dense(32,activation='relu',kernel_regularizer=l2(0.0001))(bilstm_layer)\n",
    "dropout_layer = Dropout(0.25)(dense_layer_1)\n",
    "dense_layer_2 = Dense(16,activation='relu',kernel_regularizer=l2(0.0001))(dropout_layer)\n",
    "output=TimeDistributed(Dense(1,activation='sigmoid'))(dense_layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f65028e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=[text_input,sentiment_input],outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "52b8a343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 33)           0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 33, 300)      6213000     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 33, 256)      439296      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 33, 32)       8224        bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 33, 32)       0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 33, 16)       528         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 33, 1)        17          dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,661,065\n",
      "Trainable params: 448,065\n",
      "Non-trainable params: 6,213,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6c3c7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = (df_text_train, df_sentiment_train)\n",
    "train_output = y_train\n",
    "\n",
    "valid_input = (df_text_valid,df_sentiment_valid)\n",
    "valid_output = y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92f12684",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom loss function\n",
    "\n",
    "## source : nlp_attention_mechanism assignment\n",
    "\n",
    "def loss_function(real,pred):\n",
    "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
    "    why are we using this, can't we use simple binary crossentropy?\n",
    "    Yes, you can use simple binary crossentropy , but in this loss function we are ignoring the loss\n",
    "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
    "    during preprocessing to make equal length for all the sentences.\n",
    "\n",
    "    \"\"\"\n",
    "    loss_object = tf.keras.losses.BinaryCrossentropy(reduction = tf.keras.losses.Reduction.SUM)\n",
    "    loss_ = loss_object(real,pred)\n",
    "    return loss_ / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb2ba14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file 'checkpt11' already exists.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "! mkdir  'checkpt11'\n",
    "file_path = os.path.join('model111.hdf5')\n",
    "earlystop = EarlyStopping(monitor='val_mae', min_delta=0.001, patience=10, verbose=1,mode='min')\n",
    "\n",
    "reducelr = ReduceLROnPlateau(monitor='val_mae', min_delta=0.001, patience=5, verbose=1, factor=0.9)\n",
    "checkpt_model = tf.keras.callbacks.ModelCheckpoint(filepath=file_path,save_weights_only=True,monitor='val_mae',save_best_only=True,verbose=1)\n",
    "callbacks=[checkpt_model,earlystop,reducelr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c2e30f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=loss_function,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f54fcf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "172/172 [==============================] - 132s 717ms/step - loss: 5.5034 - accuracy: 0.7767 - val_loss: 2.7395 - val_accuracy: 0.8292\n",
      "WARNING:tensorflow:Can save best model only with val_mae available, skipping.\n",
      "Epoch 2/15\n",
      "172/172 [==============================] - 121s 703ms/step - loss: 2.5513 - accuracy: 0.8302 - val_loss: 2.3614 - val_accuracy: 0.8348\n",
      "WARNING:tensorflow:Can save best model only with val_mae available, skipping.\n",
      "Epoch 3/15\n",
      "172/172 [==============================] - 120s 698ms/step - loss: 2.3537 - accuracy: 0.8352 - val_loss: 2.2604 - val_accuracy: 0.8393\n",
      "WARNING:tensorflow:Can save best model only with val_mae available, skipping.\n",
      "Epoch 4/15\n",
      "172/172 [==============================] - 121s 701ms/step - loss: 2.2692 - accuracy: 0.8398 - val_loss: 2.2248 - val_accuracy: 0.8396\n",
      "WARNING:tensorflow:Can save best model only with val_mae available, skipping.\n",
      "Epoch 5/15\n",
      "172/172 [==============================] - 120s 700ms/step - loss: 2.2287 - accuracy: 0.8420 - val_loss: 2.2176 - val_accuracy: 0.8425\n",
      "WARNING:tensorflow:Can save best model only with val_mae available, skipping.\n",
      "Epoch 6/15\n",
      "172/172 [==============================] - 120s 699ms/step - loss: 2.1914 - accuracy: 0.8440 - val_loss: 2.1778 - val_accuracy: 0.8427\n",
      "WARNING:tensorflow:Can save best model only with val_mae available, skipping.\n",
      "Epoch 7/15\n",
      "172/172 [==============================] - 121s 702ms/step - loss: 2.1492 - accuracy: 0.8453 - val_loss: 2.1544 - val_accuracy: 0.8431\n",
      "WARNING:tensorflow:Can save best model only with val_mae available, skipping.\n",
      "Epoch 8/15\n",
      "172/172 [==============================] - 120s 698ms/step - loss: 2.1188 - accuracy: 0.8475 - val_loss: 2.1476 - val_accuracy: 0.8444\n",
      "WARNING:tensorflow:Can save best model only with val_mae available, skipping.\n",
      "Epoch 9/15\n",
      "172/172 [==============================] - 120s 699ms/step - loss: 2.0932 - accuracy: 0.8487 - val_loss: 2.2120 - val_accuracy: 0.8446\n",
      "WARNING:tensorflow:Can save best model only with val_mae available, skipping.\n",
      "Epoch 10/15\n",
      "172/172 [==============================] - 120s 698ms/step - loss: 2.0606 - accuracy: 0.8493 - val_loss: 2.2530 - val_accuracy: 0.8448\n",
      "WARNING:tensorflow:Can save best model only with val_mae available, skipping.\n",
      "Epoch 11/15\n",
      "172/172 [==============================] - 120s 698ms/step - loss: 2.0307 - accuracy: 0.8512 - val_loss: 2.1496 - val_accuracy: 0.8444\n",
      "WARNING:tensorflow:Can save best model only with val_mae available, skipping.\n",
      "Epoch 12/15\n",
      "172/172 [==============================] - 120s 699ms/step - loss: 1.9829 - accuracy: 0.8529 - val_loss: 2.1732 - val_accuracy: 0.8445\n",
      "WARNING:tensorflow:Can save best model only with val_mae available, skipping.\n",
      "Epoch 13/15\n",
      "172/172 [==============================] - 120s 699ms/step - loss: 1.9498 - accuracy: 0.8535 - val_loss: 2.2558 - val_accuracy: 0.8430\n",
      "WARNING:tensorflow:Can save best model only with val_mae available, skipping.\n",
      "Epoch 14/15\n",
      "172/172 [==============================] - 120s 698ms/step - loss: 1.9120 - accuracy: 0.8570 - val_loss: 2.2267 - val_accuracy: 0.8431\n",
      "WARNING:tensorflow:Can save best model only with val_mae available, skipping.\n",
      "Epoch 15/15\n",
      "172/172 [==============================] - 120s 700ms/step - loss: 1.8715 - accuracy: 0.8598 - val_loss: 2.2612 - val_accuracy: 0.8410\n",
      "WARNING:tensorflow:Can save best model only with val_mae available, skipping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x167204e25b0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_input,train_output,epochs=15,batch_size=128,validation_data=(valid_input,valid_output),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4cbdc2",
   "metadata": {},
   "source": [
    "## Jaccard-Score for Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c8dc7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21956, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_new = X_train[[\"text\",\"selected_text\",\"sentiment\"]]\n",
    "train_data_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c9c74d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of predicted data :  (21956, 33)\n"
     ]
    }
   ],
   "source": [
    "y_train_prediction = model.predict(train_input)\n",
    "y_train_prediction = np.squeeze(y_train_prediction)\n",
    "y_train_prediction = np.round(y_train_prediction)\n",
    "print('the shape of predicted data : ',y_train_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "605fb517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 21956/21956 [00:01<00:00, 11449.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of predicted list is :  21956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## printing the predicted output as an array of index where common words present in text and selected_text\n",
    "train_data_prediction = []\n",
    "for i in tqdm(y_train_prediction):\n",
    "    index = []\n",
    "    for j in range(len(i)):\n",
    "        if i[j] == 1:\n",
    "            index.append(j)\n",
    "        else:\n",
    "            continue\n",
    "    index = np.array(index)\n",
    "    train_data_prediction.append(index)\n",
    "print('The length of predicted list is : ',len(train_data_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e662ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prediction_arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9772</th>\n",
       "      <td>someone take me to la i need to see the lemon ...</td>\n",
       "      <td>someone take me to la i need to see the lemon ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26215</th>\n",
       "      <td>lol heeeyyy love not much working and you</td>\n",
       "      <td>lol heeeyyy love not much working and you</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "9772   someone take me to la i need to see the lemon ...   \n",
       "26215          lol heeeyyy love not much working and you   \n",
       "\n",
       "                                           selected_text sentiment  \\\n",
       "9772   someone take me to la i need to see the lemon ...   neutral   \n",
       "26215          lol heeeyyy love not much working and you   neutral   \n",
       "\n",
       "                               prediction_arr  \n",
       "9772   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]  \n",
       "26215                [0, 1, 2, 3, 4, 5, 6, 7]  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_new['prediction_arr'] = train_data_prediction\n",
    "train_data_new.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee378015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converting_to_text(data):\n",
    "    \"\"\" This function convert the respective index number to its corresponding words\"\"\"\n",
    "    predicting_text  = []\n",
    "    text_column = data[0].split()\n",
    "    index = data[1]\n",
    "    l = len(text_column)\n",
    "    for i in index:\n",
    "        if i < 1:\n",
    "            predicting_text.append(text_column[i])\n",
    "    return predicting_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "95b7c007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 21956/21956 [00:00<00:00, 47566.58it/s]\n"
     ]
    }
   ],
   "source": [
    "train_prediction = train_data_new[['text','prediction_arr']].progress_apply(lambda i : converting_to_text(i),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4f2a836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prediction_arr</th>\n",
       "      <th>predicted_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9772</th>\n",
       "      <td>someone take me to la i need to see the lemon ...</td>\n",
       "      <td>someone take me to la i need to see the lemon ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]</td>\n",
       "      <td>someone take me to la i need to see the lemon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26215</th>\n",
       "      <td>lol heeeyyy love not much working and you</td>\n",
       "      <td>lol heeeyyy love not much working and you</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>lol heeeyyy love not much working and you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "9772   someone take me to la i need to see the lemon ...   \n",
       "26215          lol heeeyyy love not much working and you   \n",
       "\n",
       "                                           selected_text sentiment  \\\n",
       "9772   someone take me to la i need to see the lemon ...   neutral   \n",
       "26215          lol heeeyyy love not much working and you   neutral   \n",
       "\n",
       "                               prediction_arr  \\\n",
       "9772   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]   \n",
       "26215                [0, 1, 2, 3, 4, 5, 6, 7]   \n",
       "\n",
       "                                          predicted_text  \n",
       "9772   someone take me to la i need to see the lemon ...  \n",
       "26215          lol heeeyyy love not much working and you  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_new['predicted_text'] = train_prediction\n",
    "train_data_new['predicted_text'] = train_data_new['predicted_text'].apply(lambda i : ' '.join(i))\n",
    "train_data_new.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f124ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(x): \n",
    "    str1 = str(x[0])\n",
    "    str2 = str(x[1])\n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "16e90566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 21956/21956 [00:00<00:00, 53054.07it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_new['jaccard_score'] = train_data_new[['selected_text','predicted_text']].progress_apply(jaccard,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0fce39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean jaccard score for training data: 0.7012217438805324\n"
     ]
    }
   ],
   "source": [
    "print('Mean jaccard score for training data:', np.mean(train_data_new['jaccard_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0e87c3",
   "metadata": {},
   "source": [
    "## Jaccard-Score on Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d17bced7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5489, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data_new = X_valid[[\"text\",\"selected_text\",\"sentiment\"]]\n",
    "valid_data_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ebc9e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of predicted data :  (5489, 33)\n"
     ]
    }
   ],
   "source": [
    "y_valid_prediction = model.predict(valid_input)\n",
    "y_valid_prediction = np.squeeze(y_valid_prediction)\n",
    "y_valid_prediction = np.round(y_valid_prediction)\n",
    "print('the shape of predicted data : ',y_valid_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f9a8d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 5489/5489 [00:00<00:00, 10967.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of predicted list is :  5489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## printing the predicted output as an array of index where common words present in text and selected_text\n",
    "valid_data_prediction = []\n",
    "for i in tqdm(y_valid_prediction):\n",
    "    index = []\n",
    "    for j in range(len(i)):\n",
    "        if i[j] == 1:\n",
    "            index.append(j)\n",
    "        else:\n",
    "            continue\n",
    "    index = np.array(index)\n",
    "    valid_data_prediction.append(index)\n",
    "print('The length of predicted list is : ',len(valid_data_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21e07edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prediction_arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>sooo glad im home floridia was fun back in atl...</td>\n",
       "      <td>glad</td>\n",
       "      <td>positive</td>\n",
       "      <td>[1, 4, 5, 6, 7, 8, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11297</th>\n",
       "      <td>csi ny comes back to aus with ` CURSE lies and...</td>\n",
       "      <td>csi ny comes back to aus with ` CURSE lies and...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "1366   sooo glad im home floridia was fun back in atl...   \n",
       "11297  csi ny comes back to aus with ` CURSE lies and...   \n",
       "\n",
       "                                           selected_text sentiment  \\\n",
       "1366                                                glad  positive   \n",
       "11297  csi ny comes back to aus with ` CURSE lies and...   neutral   \n",
       "\n",
       "                                          prediction_arr  \n",
       "1366                              [1, 4, 5, 6, 7, 8, 11]  \n",
       "11297  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data_new['prediction_arr'] = valid_data_prediction\n",
    "valid_data_new.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25410f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 5489/5489 [00:00<00:00, 47160.22it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_prediction = valid_data_new[['text','prediction_arr']].progress_apply(lambda i : converting_to_text(i),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4aefc9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prediction_arr</th>\n",
       "      <th>predicted_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>sooo glad im home floridia was fun back in atl...</td>\n",
       "      <td>glad</td>\n",
       "      <td>positive</td>\n",
       "      <td>[1, 4, 5, 6, 7, 8, 11]</td>\n",
       "      <td>glad floridia was fun back in to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11297</th>\n",
       "      <td>csi ny comes back to aus with ` CURSE lies and...</td>\n",
       "      <td>csi ny comes back to aus with ` CURSE lies and...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>csi ny comes back to aus with ` CURSE lies and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "1366   sooo glad im home floridia was fun back in atl...   \n",
       "11297  csi ny comes back to aus with ` CURSE lies and...   \n",
       "\n",
       "                                           selected_text sentiment  \\\n",
       "1366                                                glad  positive   \n",
       "11297  csi ny comes back to aus with ` CURSE lies and...   neutral   \n",
       "\n",
       "                                          prediction_arr  \\\n",
       "1366                              [1, 4, 5, 6, 7, 8, 11]   \n",
       "11297  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "\n",
       "                                          predicted_text  \n",
       "1366                    glad floridia was fun back in to  \n",
       "11297  csi ny comes back to aus with ` CURSE lies and...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data_new['predicted_text'] = valid_prediction\n",
    "valid_data_new['predicted_text'] = valid_data_new['predicted_text'].apply(lambda i : ' '.join(i))\n",
    "valid_data_new.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28a5bf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 5489/5489 [00:00<00:00, 50136.62it/s]\n"
     ]
    }
   ],
   "source": [
    "valid_data_new['jaccard_score'] = valid_data_new[['selected_text','predicted_text']].progress_apply(jaccard,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e92c126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean jaccard score for validation data: 0.6525068261113721\n"
     ]
    }
   ],
   "source": [
    "print('Mean jaccard score for validation data:', np.mean(valid_data_new['jaccard_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59defba1",
   "metadata": {},
   "source": [
    "## Predicting \"selected_text\" on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6268f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>last session of the day</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  f87dea47db                            last session of the day   neutral\n",
       "1  96d74cb729  shanghai is also really exciting precisely sky...  positive"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fe4641",
   "metadata": {},
   "source": [
    "#### Tokenizing and pad sequencing Text Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ac742f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of test text :  (3533, 32)\n"
     ]
    }
   ],
   "source": [
    "df_text_test = df_test['text'].values\n",
    "df_text_test = text_tknz.texts_to_sequences(df_text_test)\n",
    "df_text_test = pad_sequences(df_text_test,maxlen=text_max_length,padding='post')\n",
    "print('the shape of test text : ',df_text_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b54d1d",
   "metadata": {},
   "source": [
    "#### Tokenizing and pad sequencing sentiment column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3dd510f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of test sentiment :  (3533, 1)\n"
     ]
    }
   ],
   "source": [
    "df_sentiment_test = df_test['sentiment'].values\n",
    "df_sentiment_test = sentiment_tknz.texts_to_sequences(df_sentiment_test)\n",
    "df_sentiment_test = pad_sequences(df_sentiment_test,maxlen=sentiment_max_length,padding='post')\n",
    "print('the shape of test sentiment : ',df_sentiment_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e8cc4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_results  = model.predict([df_text_test,df_sentiment_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f3c279fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3533, 33, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "170f6638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of predicted data :  (3533, 33)\n"
     ]
    }
   ],
   "source": [
    "predicted_results = np.squeeze(predicted_results)\n",
    "predicted_results = np.round(predicted_results)\n",
    "print('the shape of predicted data : ',predicted_results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "701e4185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3533/3533 [00:00<00:00, 10620.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of predicted list is :  3533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## printing the predicted output as an array of index where common words present in text and selected_text\n",
    "test_data_prediction = []\n",
    "for i in tqdm(predicted_results):\n",
    "    index = []\n",
    "    for j in range(len(i)):\n",
    "        if i[j] == 1:\n",
    "            index.append(j)\n",
    "        else:\n",
    "            continue\n",
    "    index = np.array(index)\n",
    "    test_data_prediction.append(index)\n",
    "print('The length of predicted list is : ',len(test_data_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dc893a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "10a44c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>prediction_arr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>last session of the day</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[0, 1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment  \\\n",
       "0  f87dea47db                            last session of the day   neutral   \n",
       "1  96d74cb729  shanghai is also really exciting precisely sky...  positive   \n",
       "\n",
       "    prediction_arr  \n",
       "0  [0, 1, 2, 3, 4]  \n",
       "1              [4]  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['prediction_arr'] = test_data_prediction\n",
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cb6f3e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 3533/3533 [00:00<00:00, 34048.40it/s]\n"
     ]
    }
   ],
   "source": [
    "test_prediction = test_data[['text','prediction_arr']].progress_apply(lambda i : converting_to_text(i),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d9f4df09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>last session of the day</td>\n",
       "      <td>neutral</td>\n",
       "      <td>last session of the day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>shanghai is also really exciting precisely sky...</td>\n",
       "      <td>positive</td>\n",
       "      <td>exciting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>recession hit veronique branquinho she has to ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>a shame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday</td>\n",
       "      <td>positive</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>i like it</td>\n",
       "      <td>positive</td>\n",
       "      <td>i like it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment  \\\n",
       "0  f87dea47db                            last session of the day   neutral   \n",
       "1  96d74cb729  shanghai is also really exciting precisely sky...  positive   \n",
       "2  eee518ae67  recession hit veronique branquinho she has to ...  negative   \n",
       "3  01082688c6                                         happy bday  positive   \n",
       "4  33987a8ee5                                          i like it  positive   \n",
       "\n",
       "             selected_text  \n",
       "0  last session of the day  \n",
       "1                 exciting  \n",
       "2                  a shame  \n",
       "3                    happy  \n",
       "4                i like it  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['selected_text'] = test_prediction\n",
    "test_data['selected_text'] = test_data['selected_text'].apply(lambda i : ' '.join(i))\n",
    "test_data = test_data.drop('prediction_arr',axis=1)\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcb72a4",
   "metadata": {},
   "source": [
    "### Observations/Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab1b5dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------+---------------------+--------------------------+\n",
      "|                     Model                      | Train_Jaccard_score | Validation_Jaccard_score |\n",
      "+------------------------------------------------+---------------------+--------------------------+\n",
      "|                LSTM Base Model                 |        0.5037       |          0.492           |\n",
      "|  BiDirectional LSTM Seq2Seq Glove Embedding    |        0.701        |          0.652           |\n",
      "| BiDirectional LSTM Seq2Seq FastText Embedding  |        0.671        |          0.651           |\n",
      "+------------------------------------------------+---------------------+--------------------------+\n"
     ]
    }
   ],
   "source": [
    "# for Fasttext embedding result shown here please refer Bidirectional_lstm_seq2seq_model_fasttext_embedding.ipynb file\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "result = PrettyTable()\n",
    "result.field_names = [\"Model\",\"Train_Jaccard_score\",\"Validation_Jaccard_score\"]\n",
    "result.add_row([\"LSTM Base Model\",0.5037,0.492])\n",
    "result.add_row([\"BiDirectional LSTM Seq2Seq Glove Embedding \",0.701,0.652])\n",
    "result.add_row([\"BiDirectional LSTM Seq2Seq FastText Embedding \",0.671,0.651])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ba83e6",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "we can see that BiDirectional LSTM with glove embedding method has improved the jaccard score very much as compare to base model and also the performance by using using fast-text embedding is almost same.In ordr to come in top 10% in kaggle competition we must have jaccard score of 0.71705.<br>Next to improve result we will use concept of adding attention layers or encoder-decoder layers whichever will able to apply from links given below:<br>\n",
    "https://www.appliedaicourse.com/lecture/11/applied-machine-learning-online-course/4150/attention-models-in-deep-learning/8/module-8-neural-networks-computer-vision-and-deep-learning\n",
    "<br>\n",
    "\n",
    "https://www.appliedaicourse.com/lecture/11/applied-machine-learning-online-course/4149/live-encoder-decoder-models/8/module-8-neural-networks-computer-vision-and-deep-learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bffbded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
